\documentclass[11pt]{article}
\usepackage[left=1.25in,top=1in,right=1.25in,bottom=1.00in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
\usepackage{hyperref}

\usepackage{epsfig}
\usepackage{color}
\usepackage[round]{natbib}
\usepackage{multirow} 
\newcommand{\logit}{\mbox{logit}}
\newcommand{\probit}{\mbox{probit}}
\newcommand{\hiw}{{\small\textsc{HIW}}}
\newcommand{\iw}{{\small\textsc{IW}}}
\newcommand{\N}{\mbox{N}}
\newcommand{\Be}{\mbox{Be}}
\newcommand{\dd}{\mbox{d}}
\newcommand{\C}{\; | \;}
\newcommand{\var}{\text{var}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}




\begin{document}

\title{{\bf Homework Assignment 1}\\Due via canvas Feb 17th}
\author{SDS 384-11 Theoretical Statistics}

\date{}

\maketitle{}
%\textbf{Set algebra and probability laws.}
\begin{enumerate}%\item Read Bertsekas and Tsitsiklis, sections 1.1, 1.2 and 1.3.
%\section{Jeffrey's prior}
%\begin{enumerate}
%\end{enumerate}
%\item	Given densities $p_n$ and $q_n$ with respect to some measure $\mu$, let $X$ be distributed according to the distribution with density $p_n$. Define the likelihood ratio $L_n(X)$ as $L_n(X) = q_n(X)/p_n(X)$ for $p_n(X) > 0$. $L_n(X) = 1$. if $p_n(X) = q_n(X) = 0$ and $L_n(X) = \infty$ otherwise. Show that the likelihood ratio is a uniformly tight sequence.
\item Consider a sequence of iid random variables $\{X_n\}$ such that $X_i\sim Beta(\theta,1)$, where $\theta>0$. Let $\bar{X}_n$ denote the sample mean. The method of moments estimator of $\theta$ is $\hat{\theta}_n=\bar{X}_n/(1-\bar{X}_n)$. Derive the asymptotic distribution of $\sqrt{n}(\hat{\theta}_n-\theta)$.
\item We will do some examples of convergence in distribution and convergence in probability here.
\begin{enumerate}
	\item Let $X_n\sim N(0,1/n)$. Does $X_n\stackrel{d}{\rightarrow} 0$?
	\item  Let $\{X_n\}$ be independent r.v's such that $P(X_n=n^\alpha)=1/n$ and $P(X_n=0)=1-1/n$ for $n\geq 1$, where $\alpha\in (-\infty,infty)$ is a constant. For what values of $\alpha$, will you have $X_n\stackrel{q.m}{\rightarrow} 0$? For what values will you have $X_n\stackrel{p}{\rightarrow} 0$?
\end{enumerate}
\item If $X_n\stackrel{d}{\rightarrow} X\sim Poisson(\lambda)$, is it necessarily true that $E[g(X_n)]\rightarrow E[g(X)]$?
\begin{enumerate}
	\item $g(x)=1(x\in (0,10))$
	\item $g(x)=e^{-x^2}$
	\item $g(x)=sgn(cos(x))$ [$sgn(x)=1$ if $x>0$, $-1$ if $x<0$ and $0$ if $x=0$.]
	\item $g(x)=x$
\end{enumerate}
\item Let $X_1,\dots, X_n$ be independent r.v's with mean zero and variance $\sigma_i^2:=E[X_i^2]$ and $s_n^2=\sum_i\sigma_i^2$. If $\exists\delta>0$ s.t. as $n\rightarrow\infty$,
$$\frac{\sum_i E|X_i|^{2+\delta}}{s_n^{2+\delta}}\rightarrow 0,$$
then $\sum_i X_i/s_n$ converges weakly to the standard normal.
\item Recall the converse of the Lindeberg Feller theorem. We will gather some intuition about that here. Let $X_1,\dots, X_n$ be independent r.v's with mean zero and variance $\sigma_i^2:=E[X_i^2]$ and $s_n^2=\sum_i\sigma_i^2$. 
\begin{enumerate}
	\item If $\max_i \sigma_i^2/s_n^2$ does not converge to zero as $n\rightarrow\infty$, then the Lindeberg condition does not hold. 
	\item Construct an example where the above is true, but still we have $\sum_iX_i/s_n$ converges weakly to $N(0,1)$. This shows that the Lindeberg condition is not necessary. You can show this by showing that the moment generating function converges to that of a standard normal.
\end{enumerate}
%\item Consider $r$ balls 
%\item Consider $n$ i.i.d random variables $\{X_n\}$ uniformly distributed on the set of $n$ points $\{1/n,2/n,\dots,1\}$. Show that $X_n\stackrel{d}{\rightarrow} X$ where $X\sim Uniform(0,1)$. Does $X_n\stackrel{P}{\rightarrow}X$?
\end{enumerate}
\end{document} 
